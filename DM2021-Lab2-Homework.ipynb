{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 蕭靖澂 Ching-Cheng Hsiao\n",
    "\n",
    "Student ID: 110033632\n",
    "\n",
    "GitHub ID: hsiaooo\n",
    "\n",
    "Kaggle name:\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2021-Lab2-master Repo](https://github.com/fhcalderon87/DM2021-Lab2-master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/c/dm2021-lab2-hw2/) regarding Emotion Recognition on Twitter. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 24th 11:59 pm, Friday)__. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 29th 11:59 pm, Wednesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the json\n",
    "path       = os.path.dirname(os.path.abspath(\"tweets_DM.json\"))\n",
    "# raw_data = pd.read_json(path+\"/dataset/tweets_DM.json\",lines=True)\n",
    "# tweets   = pd.json_normalize(data=raw_data['_source'])\n",
    "# identify = pd.read_csv(basePath+\"/dataset/data_identification.csv\")\n",
    "# emotion  = pd.read_csv(basePath+\"/dataset/emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rename column names\n",
    "# tweets = tweets.rename(index=str, columns={\"tweet.text\":\"text\", \"tweet.tweet_id\":\"tweet_id\", \"tweet.hashtags\":\"hashtags\"})\n",
    "\n",
    "# # add identify tags to dataframe\n",
    "# tweets = pd.merge(tweets, identify, on=\"tweet_id\")\n",
    "\n",
    "# tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get training set and test set\n",
    "# train_df = tweets[tweets[\"identification\"] == \"train\"]\n",
    "# test_df  = tweets[tweets[\"identification\"] == \"test\"]\n",
    "\n",
    "# # drop identification tags\n",
    "# train_df.drop(columns=[\"identification\"], inplace=True)\n",
    "# test_df.drop(columns=[\"identification\"], inplace=True)\n",
    "\n",
    "# print(f'Training set\\n{train_df.head()}\\n')\n",
    "# print(f'Testing set\\n{test_df.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add emotion column\n",
    "# train_df = pd.merge(train_df, emotion, on=\"tweet_id\")\n",
    "# test_df = test_df.assign(emotion=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tweet_id as index\n",
    "# train_df.set_index(\"tweet_id\",inplace=True)\n",
    "# test_df.set_index(\"tweet_id\",inplace=True)\n",
    "\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "# train_df.to_pickle(\"train_df.pkl\")\n",
    "# test_df.to_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pickle file\n",
    "train_df = pd.read_pickle(path+\"/train_df.pkl\")\n",
    "test_df = pd.read_pickle(path+\"/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=20000, stop_words='english',\n",
       "                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f2afeefeaf0>>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tknzr = TweetTokenizer(preserve_case=False)\n",
    "tfidf = TfidfVectorizer(max_features=20000, stop_words='english', tokenizer=tknzr.tokenize)\n",
    "\n",
    "# fitting\n",
    "tfidf.fit(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 20000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming training sets\n",
    "X_train = tfidf.transform(train_df['text'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972, 20000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming testing sets\n",
    "X_test = tfidf.transform(test_df['text'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pointers\n",
    "y_train = train_df['emotion']\n",
    "y_test = test_df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id\n",
      "0x28b412    \n",
      "0x2de201    \n",
      "0x218443    \n",
      "0x2939d5    \n",
      "Name: emotion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id\n",
      "0x376b20    0\n",
      "0x2d5350    1\n",
      "0x1cd5b0    2\n",
      "0x1d755c    3\n",
      "0x2c91a8    0\n",
      "           ..\n",
      "0x321566    3\n",
      "0x38959e    3\n",
      "0x2cbca6    3\n",
      "0x24faed    3\n",
      "0x34be8c    3\n",
      "Name: emotion, Length: 1455563, dtype: object\n",
      "anger \t\t=  4\n",
      "anticipation \t=  0\n",
      "disgust \t=  6\n",
      "fear \t\t=  2\n",
      "joy \t\t=  3\n",
      "sadness \t=  1\n",
      "surprise \t=  7\n",
      "trust \t\t=  5\n"
     ]
    }
   ],
   "source": [
    "emotion = pd.Categorical(y_train.iloc[:], categories=y_train.iloc[:].unique(), ordered=True)\n",
    "\n",
    "y_train.iloc[:] = emotion.codes\n",
    "print(y_train)\n",
    "print('anger \\t\\t= ', y_train[9])\n",
    "print('anticipation \\t= ', y_train[0])\n",
    "print('disgust \\t= ', y_train[18])\n",
    "print('fear \\t\\t= ', y_train[2])\n",
    "print('joy \\t\\t= ', y_train[3])\n",
    "print('sadness \\t= ', y_train[1])\n",
    "print('surprise \\t= ', y_train[19])\n",
    "print('trust \\t\\t= ', y_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgbc = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 1 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "pred_result_xgbc = xgbc.predict(X_test)\n",
    "\n",
    "pred_result_xgbc.shape\n",
    "print(pred_result_xgbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 0 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(pred_result_xgbc[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = []\n",
    "for i, emo in enumerate(pred_result_xgbc):\n",
    "    if emo == 0:\n",
    "        pred_result.append('anticipation')\n",
    "    elif emo == 1:\n",
    "        pred_result.append('sadness')\n",
    "    elif emo == 2:\n",
    "        pred_result.append('fear')\n",
    "    elif emo == 3:\n",
    "        pred_result.append('joy')\n",
    "    elif emo == 4:\n",
    "        pred_result.append('anger')\n",
    "    elif emo == 5:\n",
    "        pred_result.append('trust')\n",
    "    elif emo == 6:\n",
    "        pred_result.append('fear')\n",
    "    elif emo == 7:\n",
    "        pred_result.append('surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'anticipation' 'sadness' ... 'joy' 'joy' 'joy']\n"
     ]
    }
   ],
   "source": [
    "pred = np.array(pred_result)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file!\n"
     ]
    }
   ],
   "source": [
    "# save the result\n",
    "test_df['emotion'] = pred\n",
    "test_df.drop(columns = ['hashtags','text'],inplace=True)\n",
    "test_df.index.rename('id',inplace=True)\n",
    "test_df.columns = ['emotion']\n",
    "test_df.to_csv(path+'/submission/xgbc_tfidf.csv')\n",
    "print('Saved file!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 23:28:38.445317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-20 23:28:38.445336: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import rmsprop_v2\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pickle file\n",
    "train_df = pd.read_pickle(path+\"/train_df.pkl\")\n",
    "test_df = pd.read_pickle(path+\"/test_df.pkl\")\n",
    "\n",
    "# set pointers\n",
    "y_train = train_df['emotion']\n",
    "y_test = test_df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 300\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 300)\n",
      "(411972, 300)\n"
     ]
    }
   ],
   "source": [
    "train_seq = tok.texts_to_sequences(train_df['text'])\n",
    "test_seq = tok.texts_to_sequences(test_df['text'])\n",
    "\n",
    "train_seq_mat = sequence.pad_sequences(train_seq,maxlen=max_len)\n",
    "test_seq_mat = sequence.pad_sequences(test_seq,maxlen=max_len)\n",
    "\n",
    "print(train_seq_mat.shape)\n",
    "print(test_seq_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " tweet_id\n",
      "0x376b20    anticipation\n",
      "0x2d5350         sadness\n",
      "0x1cd5b0            fear\n",
      "0x1d755c             joy\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (1455563,)\n",
      "y_test.shape:  (411972,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (1455563, 8)\n",
      "y_test.shape:  (411972,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return np_utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "# y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id\n",
      "0x376b20    0\n",
      "0x2d5350    1\n",
      "0x1cd5b0    2\n",
      "0x1d755c    3\n",
      "0x2c91a8    0\n",
      "           ..\n",
      "0x321566    3\n",
      "0x38959e    3\n",
      "0x2cbca6    3\n",
      "0x24faed    3\n",
      "0x34be8c    3\n",
      "Name: emotion, Length: 1455563, dtype: object\n",
      "tweet_id\n",
      "0x28b412    0\n",
      "0x2de201    0\n",
      "0x218443    0\n",
      "0x2939d5    0\n",
      "0x26289a    0\n",
      "           ..\n",
      "0x2913b4    0\n",
      "0x2a980e    0\n",
      "0x316b80    0\n",
      "0x29d0cb    0\n",
      "0x2a6a4f    0\n",
      "Name: emotion, Length: 411972, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_emotion = pd.Categorical(y_train.iloc[:], categories=y_train.iloc[:].unique(), ordered=True)\n",
    "test_emotion = pd.Categorical(y_test.iloc[:], categories=y_test.iloc[:].unique(), ordered=True)\n",
    "\n",
    "y_train.iloc[:] = train_emotion.codes\n",
    "y_test.iloc[:] = test_emotion.codes\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  20000\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 00:06:23.717206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 00:06:23.717624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:06:23.717670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:06:23.717706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:06:23.719665: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:06:23.719719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:06:23.719756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-12-21 00:06:23.719765: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-21 00:06:23.720004: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 300, 128)          2560128   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " FC2 (Dense)                 (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,709,256\n",
      "Trainable params: 2,709,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(name='inputs',shape=[max_len])\n",
    "## Embedding\n",
    "layer = Embedding(max_words+1,128,input_length=max_len)(inputs)\n",
    "layer = LSTM(128)(layer)\n",
    "layer = Dense(128,activation=\"relu\",name=\"FC1\")(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(output_shape,activation=\"softmax\",name=\"FC2\")(layer)\n",
    "model = Model(inputs=inputs,outputs=layer)\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=rmsprop_v2.RMSprop(),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 00:06:27.996905: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1746675600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1990/11372 [====>.........................] - ETA: 51:00 - loss: 1.4099 - accuracy: 0.4931"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_seq_mat, y_train,batch_size=128, epochs=3, callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the result using our model\n",
    "pred_result_lstm = label_decode(label_encoder, model.predict(test_seq_mat, batch_size=128))\n",
    "pred_result_lstm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "test_df['emotion']=pred_result_lstm\n",
    "test_df.drop(columns=['hashtags','text'],inplace=True)\n",
    "test_df.index.rename('id',inplace=True)\n",
    "test_df.columns=['emotion']\n",
    "test_df.to_csv(path+'/submission/keras_tfidf.csv')\n",
    "print('Saved file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
